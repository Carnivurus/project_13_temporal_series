{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción del proyecto\n",
    "\n",
    "La compañía Sweet Lift Taxi ha recopilado datos históricos sobre pedidos de taxis en los aeropuertos. Para atraer a más conductores durante las horas pico, necesitamos predecir la cantidad de pedidos de taxis para la próxima hora. Construye un modelo para dicha predicción.\n",
    "\n",
    "La métrica RECM en el conjunto de prueba no debe ser superior a 48.\n",
    "\n",
    "## Instrucciones del proyecto.\n",
    "\n",
    "1. Descarga los datos y haz el remuestreo por una hora.\n",
    "2. Analiza los datos\n",
    "3. Entrena diferentes modelos con diferentes hiperparámetros. La muestra de prueba debe ser el 10% del conjunto de datos inicial.4. Prueba los datos usando la muestra de prueba y proporciona una conclusión.\n",
    "\n",
    "## Descripción de los datos\n",
    "\n",
    "Los datos se almacenan en el archivo `taxi.csv`. \t\n",
    "El número de pedidos está en la columna `num_orders`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definir el tipo de proyecto\n",
    "\n",
    "De acuerdo a las caracteristicas mencionadas del proycto, nos encontramos ante un objetivo de predicción a través de modelos de regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from pmdarima.arima import auto_arima\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importación de dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/datasets/taxi.csv',parse_dates=   ,index_col=)\n",
    "df = pd.read_csv('D:/Tripleten/datasets/taxi.csv', index_col='datetime', parse_dates=[0] ) #\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visión general del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     num_orders\n",
      "datetime                       \n",
      "2018-03-01 00:00:00           9\n",
      "2018-03-01 00:10:00          14\n",
      "2018-03-01 00:20:00          28\n",
      "2018-03-01 00:30:00          20\n",
      "2018-03-01 00:40:00          32\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 26496 entries, 2018-03-01 00:00:00 to 2018-08-31 23:50:00\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   num_orders  26496 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 414.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(df.head(), end='\\n\\n')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revision de duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Revisión de valores nulos\n",
    "\n",
    "De acuerdo con df.info() no existen valores nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coherencia de datos\n",
    "\n",
    "Los datos mantienen una tendencia de crecimiento, por el momento muestran coherencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_orders</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-04</th>\n",
       "      <td>5301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-11</th>\n",
       "      <td>9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-18</th>\n",
       "      <td>9785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-25</th>\n",
       "      <td>9767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-01</th>\n",
       "      <td>9752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-08</th>\n",
       "      <td>9377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-15</th>\n",
       "      <td>10352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-22</th>\n",
       "      <td>11224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-29</th>\n",
       "      <td>12041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-06</th>\n",
       "      <td>10948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            num_orders\n",
       "datetime              \n",
       "2018-03-04        5301\n",
       "2018-03-11        9411\n",
       "2018-03-18        9785\n",
       "2018-03-25        9767\n",
       "2018-04-01        9752\n",
       "2018-04-08        9377\n",
       "2018-04-15       10352\n",
       "2018-04-22       11224\n",
       "2018-04-29       12041\n",
       "2018-05-06       10948"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.resample('W').sum().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X] Identificar tipo de proyecto\n",
    "- [X] Nombre de columna correcta\n",
    "- [X] Clasificaciones de tipo de dato correctas\n",
    "- [X] Dataframe sin duplicados\n",
    "- [X] Excluir valores nulos\n",
    "- [X] Verificar la coherencia de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusiones del proceso de preparación.\n",
    "\n",
    "El conjunto de datos cargado mantiene una limpieza en sus datos (nombre de columna correctamente nombrados, coherencia de datos, inexistencia de duplicados y valores nulos ). Los datos cargados establecen un periodo desde el periodo 2018-03-01 hasta 2018-08-31."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.resample('YE').sum()\n",
    "df_monthly = df.resample('ME').sum()\n",
    "df_weekly = df.resample('W').sum()\n",
    "df_daily = df.resample('D').sum()\n",
    "df_hourly = df.resample('h').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles = ['Gráfico mensual', 'Gráfico semanal', 'Gráfico diario', 'Gráfico por hora']\n",
    "# interval = [1,4,24,480]\n",
    "\n",
    "# databases = [df_monthly,df_weekly,df_daily, df_hourly]\n",
    "# fig, axis = plt.subplots(4,1, figsize=[10,5])\n",
    "\n",
    "# for i, database in enumerate(databases):\n",
    "#     axis[i].plot(database.index, database.values, '--o')\n",
    "#     axis[i].set_title(titles[i])\n",
    "#     axis[i].set_xticks(database.index)\n",
    "#     axis[i].set_xticks(database.index[::interval[i]])\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed = seasonal_decompose(df_hourly, model='additive', period =7)\n",
    "# decomposed.plot()\n",
    "# plt.title('Orders Trend')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiendo función para crear mas columnas de información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df, max_lag, rolling_mean_size):\n",
    "    '''Esta función tomará una serie temporal y creara columnas para aumentar su posibilidad de predicción\n",
    "     en modelos de machine learning, generará columnas de año, mes, día, día de la semana y generará desfaces en los valores definidos \n",
    "    por la entrada, también generará una columna con el promedio móvil'''\n",
    "\n",
    "    df['year'] = df.index.year\n",
    "    df['month'] = df.index.month\n",
    "    df['day'] = df.index.day\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "\n",
    "    for lag in range(1, max_lag +1):\n",
    "        df[f'lag_{lag}'] = df['num_orders'].shift(lag)\n",
    "\n",
    "    # df['rolling_mean'] = df['num_orders'].rolling(rolling_mean_size).mean()\n",
    "    df['rolling_mean'] = df['num_orders'].shift().rolling(rolling_mean_size).mean()\n",
    "\n",
    "make_features(df_hourly,3,3)\n",
    "\n",
    "df_hourly.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y= df_hourly['num_orders']\n",
    "X= df_hourly.drop(columns='num_orders')\n",
    "\n",
    "X_train, X_test,y_train, y_test = train_test_split(X,y,shuffle=False, test_size=1/10) #10% del conjuntos de datos inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear(X_train, y_train, X_test,y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Prediciendo las muestras\n",
    "    y_predict = model.predict(X_test)\n",
    "    test_rmse_score = root_mean_squared_error(y_test,y_predict)\n",
    "\n",
    "    objective_rmse_score = root_mean_squared_error([y_test.iloc[0]],[y_predict[0]])\n",
    "\n",
    "    print(f'RMSE para muestra es:{test_rmse_score:.2f}')\n",
    "    print(f'RMSE para la siguiente hora:{objective_rmse_score:.2f}')\n",
    "    print(f'Cantidad de taxis predichos para la siguiente hora es de \"{round(y_predict[0])}\" con un error de \"{round(objective_rmse_score)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE para muestra es:52.45\n",
      "RMSE para la siguiente hora:6.02\n",
      "Cantidad de taxis predichos para la siguiente hora es de \"108\" con un error de \"6\"\n"
     ]
    }
   ],
   "source": [
    "linear(X_train, y_train, X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Auto Arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arima = df_hourly['num_orders']\n",
    "train, test = train_test_split(df_arima, shuffle=False, test_size=1/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE para muestra es:33.60\n",
      "RMSE para la siguiente hora:32.45\n",
      "Cantidad de taxis predichos para la siguiente hora es de \"134.45\" con un error de \"32\"\n"
     ]
    }
   ],
   "source": [
    "model = auto_arima(train, seasonal=True, m=12, stepwise=True)\n",
    "summary = model.summary()\n",
    "y_predict = model.predict(n_periods=5) #len(test) 442\n",
    "\n",
    "rmse_score = root_mean_squared_error(test.iloc[0:5:], y_predict)\n",
    "objective_rmse_score = root_mean_squared_error([test.iloc[0]], [y_predict.iloc[0]])\n",
    "\n",
    "print(f'RMSE para muestra es:{rmse_score:.2f}')\n",
    "print(f'RMSE para la siguiente hora:{objective_rmse_score:.2f}')\n",
    "print(f'Cantidad de taxis predichos para la siguiente hora es de \"{y_predict.iloc[0]:.2f}\" con un error de \"{round(objective_rmse_score)}\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Prophet (Meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:51:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "12:51:09 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE para muestra es:48.27\n",
      "RMSE para la siguiente hora:13.06\n",
      "Cantidad de taxis predichos para la siguiente hora es de \"115.05502204867386\" con un error de \"13\"\n"
     ]
    }
   ],
   "source": [
    "df_prophet = pd.DataFrame(data={\"ds\":df_hourly.index,\"y\":df_hourly['num_orders']})\n",
    "df_prophet = df_prophet.reset_index(drop=True)\n",
    "\n",
    "train, test =train_test_split(df_prophet, test_size=1/10, shuffle=False)\n",
    "\n",
    "model = Prophet()\n",
    "model.fit(train)\n",
    "\n",
    "# Realizar las predicciones para el conjunto de prueba\n",
    "future = model.make_future_dataframe(periods=len(test), freq='h')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "y_predict = forecast['yhat'].tail(len(test))\n",
    "rmse_score = root_mean_squared_error(test['y'],y_predict)\n",
    "objective_rmse_score = root_mean_squared_error([test['y'].iloc[0]],[y_predict.iloc[0]])\n",
    "\n",
    "print(f'RMSE para muestra es:{rmse_score:.2f}')\n",
    "print(f'RMSE para la siguiente hora:{objective_rmse_score:.2f}')\n",
    "print(f'Cantidad de taxis predichos para la siguiente hora es de \"{y_predict.iloc[0]}\" con un error de \"{round(objective_rmse_score)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Random Forest Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de revisión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook está abierto.\n",
    "- [ ]  El código no tiene errores\n",
    "- [ ]  Las celdas con el código han sido colocadas en el orden de ejecución.\n",
    "- [ ]  Los datos han sido descargados y preparados.\n",
    "- [ ]  Se ha realizado el paso 2: los datos han sido analizados\n",
    "- [ ]  Se entrenó el modelo y se seleccionaron los hiperparámetros\n",
    "- [ ]  Se han evaluado los modelos. Se expuso una conclusión\n",
    "- [ ]  La *RECM* para el conjunto de prueba no es más de 48"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
